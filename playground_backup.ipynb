{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faf41d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/users/ujjwal.upadhyay/miniconda3/envs/trans/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a1ab411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, math\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.optim import Adam\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aa74c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE_MODEL_NUMBER_OF_LAYERS = 6\n",
    "BASELINE_MODEL_DIMENSION = 512\n",
    "BASELINE_MODEL_NUMBER_OF_HEADS = 8\n",
    "BASELINE_MODEL_DROPOUT_PROB = 0.1\n",
    "BASELINE_MODEL_LABEL_SMOOTHING_VALUE = 0.1\n",
    "\n",
    "\n",
    "BIG_MODEL_NUMBER_OF_LAYERS = 6\n",
    "BIG_MODEL_DIMENSION = 1024\n",
    "BIG_MODEL_NUMBER_OF_HEADS = 16\n",
    "BIG_MODEL_DROPOUT_PROB = 0.3\n",
    "BIG_MODEL_LABEL_SMOOTHING_VALUE = 0.1\n",
    "\n",
    "\n",
    "BOS_TOKEN = '[CLS]'\n",
    "EOS_TOKEN = '[SEP]'\n",
    "PAD_TOKEN = \"[PAD]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9b75aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset opus_books (/home/users/ujjwal.upadhyay/.cache/huggingface/datasets/opus_books/en-fr/1.0.0/e8f950a4f32dc39b7f9088908216cd2d7e21ac35f893d04d39eb594746af2daf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3ad5df61d546b38556c319b6fc859e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': '110860', 'translation': {'en': 'I stopped.', 'fr': \"Je m'arrÃªtai.\"}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "books = load_dataset(\"opus_books\", \"en-fr\")\n",
    "books.cleanup_cache_files()\n",
    "books = books[\"train\"].train_test_split(test_size=0.2)\n",
    "books[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9781853d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "print(tokenizer.special_tokens_map)\n",
    "\n",
    "source_lang = \"en\"\n",
    "target_lang = \"fr\"\n",
    "prefix = \"translate English to French: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1553078c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4138fb5c5b7a4a668b815b538886a99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fbab14134004ed8b11c93c5746e4b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + example[source_lang] for example in examples[\"translation\"]]\n",
    "    targets = [example[target_lang] for example in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True, padding=True, return_special_tokens_mask=True, return_tensors='pt')\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_books = books.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0573f5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'translation', 'input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask', 'labels'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_books['train'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1728fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 128)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_books['train'][0:10]['input_ids']), len(tokenized_books['train'][0]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3954b862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'hello',\n",
       " ',',\n",
       " 'y',\n",
       " \"'\",\n",
       " 'all',\n",
       " '!',\n",
       " 'how',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = tokenizer.convert_ids_to_tokens(tokenizer.encode(\"Hello, y'all! How are you?\"))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94a7fb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_n_batches(num_batch, batch_size):\n",
    "    src_tokens, trg_tokens, src_masks, trg_masks, trg_gts = [], [], [], [], []\n",
    "    for i in tqdm(range(num_batch)):\n",
    "        src_tkn = torch.Tensor(tokenized_books['train'][0:BATCH_SIZE]['input_ids']).to(torch.IntTensor())\n",
    "        trg_tkn = torch.Tensor(tokenized_books['train'][0:BATCH_SIZE]['labels']).to(torch.IntTensor())\n",
    "#         src_mask = torch.BoolTensor(tokenized_books['train'][0:BATCH_SIZE]['attention_mask']).view(BATCH_SIZE, 1, 1, -1)\n",
    "#         trg_mask = torch.BoolTensor(torch.Tensor(tokenized_books['train'][0:BATCH_SIZE]['labels'])==1).view(BATCH_SIZE, 1, 1, -1)\n",
    "        src_mask = torch.BoolTensor(tokenized_books['train'][0:BATCH_SIZE]['attention_mask']).view(BATCH_SIZE, -1)\n",
    "        trg_mask = torch.BoolTensor(torch.Tensor(tokenized_books['train'][0:BATCH_SIZE]['labels'])==1).view(BATCH_SIZE, -1)\n",
    "        \n",
    "        label_smoothing = LabelSmoothingDistribution(BASELINE_MODEL_LABEL_SMOOTHING_VALUE, tokenizer.pad_token_id, tokenizer.vocab_size, \"cpu\")\n",
    "        trg_gt = label_smoothing(trg_tkn[:, :].reshape(-1, 1))\n",
    "        \n",
    "        src_tokens.append(src_tkn)\n",
    "        trg_tokens.append(trg_tkn)\n",
    "        src_masks.append(src_mask)\n",
    "        trg_masks.append(trg_mask)\n",
    "        trg_gts.append(trg_gt)\n",
    "\n",
    "    return src_tokens, trg_tokens, src_masks, trg_masks, trg_gts\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be492d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25d30dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of parameters: 84767546\n"
     ]
    }
   ],
   "source": [
    "from transformer import Transformer\n",
    "trans = Transformer(model_dimension=512, src_vocab_size=tokenizer.vocab_size, \n",
    "                    trg_vocab_size=tokenizer.vocab_size, \n",
    "                    number_of_heads=8, number_of_layers=4, mem_size=16,\n",
    "                    dropout_probability=0.1, log_attention_weights=False)\n",
    "trans.train()\n",
    "print(\"No of parameters:\", sum(dict((p.data_ptr(), p.numel()) for p in trans.parameters()).values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90ed7c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e0ee0b4cb34b8395e3e226bd1df54a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC TKN: torch.Size([1, 128])\n",
      "TRG TKN: torch.Size([1, 128])\n",
      "SRC MASK: torch.Size([1, 128])\n",
      "TRG_MASK: torch.Size([1, 128])\n",
      "TRG GT: torch.Size([128, 30522])\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 100\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "src_tokens, trg_tokens, src_masks, trg_masks, trg_gts = create_n_batches(num_batch=50, batch_size=BATCH_SIZE)\n",
    "\n",
    "# src_tkn = torch.Tensor(tokenized_books['train'][0:BATCH_SIZE]['input_ids']).to(torch.IntTensor())\n",
    "# trg_tkn = torch.Tensor(tokenized_books['train'][0:BATCH_SIZE]['labels']).to(torch.IntTensor())\n",
    "# src_mask = torch.BoolTensor(tokenized_books['train'][0:BATCH_SIZE]['attention_mask']).view(BATCH_SIZE, 1, 1, -1)\n",
    "# trg_mask = torch.BoolTensor(torch.Tensor(tokenized_books['train'][0:BATCH_SIZE]['labels'])==1).view(BATCH_SIZE, 1, 1, -1)\n",
    "\n",
    "# label_smoothing = LabelSmoothingDistribution(BASELINE_MODEL_LABEL_SMOOTHING_VALUE, tokenizer.pad_token_id, tokenizer.vocab_size, \"cpu\")\n",
    "# trg_gt = label_smoothing(trg_tkn[:, :].reshape(-1, 1))\n",
    "\n",
    "optimizer = optim.AdamW(trans.parameters(), lr=5e-4)\n",
    "kl_div_loss = nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "init_src_memory = trans.src_memory.clone()\n",
    "init_trg_memory = trans.trg_memory.clone()\n",
    "\n",
    "print(f\"SRC TKN: {src_tokens[0].shape}\\nTRG TKN: {trg_tokens[0].shape}\\nSRC MASK: {src_masks[0].shape}\\nTRG_MASK: {trg_masks[0].shape}\\nTRG GT: {trg_gts[0].shape}\")\n",
    "src_tkn, trg_tkn, src_mask, trg_mask, trg_gt = src_tokens[0], trg_tokens[0], src_masks[0], trg_masks[0], trg_gts[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "438f9b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h_state, log_probab = trans(src_tkn, trg_tkn, src_mask, trg_mask)\n",
    "# h_state.shape, log_probab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "304632d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9200ccfb234d4c1aa09033c90fc9e68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:10 - LOSS:0.06325589120388031\n",
      "EPOCH:20 - LOSS:0.0552356131374836\n",
      "EPOCH:30 - LOSS:0.05187438800930977\n",
      "EPOCH:40 - LOSS:0.049195390194654465\n",
      "EPOCH:50 - LOSS:0.04627738147974014\n"
     ]
    }
   ],
   "source": [
    "gradient_accumulation_steps = 10\n",
    "for i in tqdm(range(50)):\n",
    "    h_state, log_probab = trans(src_tokens[i], trg_tokens[i], src_masks[i], trg_masks[i])\n",
    "    loss = kl_div_loss(log_probab, trg_gts[i])\n",
    "    loss = loss / gradient_accumulation_steps\n",
    "    loss.backward(retain_graph=True)\n",
    "    if (i + 1) % gradient_accumulation_steps == 0:\n",
    "        print(f\"EPOCH:{i+1} - LOSS:{loss}\")\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d218c513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "print((trans.src_memory == init_src_memory).sum())\n",
    "print((trans.trg_memory == init_trg_memory).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2dc546a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isnan(trans.trg_memory).sum(), torch.isnan(trans.src_memory).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecc27246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128]) torch.Size([1, 128]) torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "bsz_test = 1\n",
    "idx = 10\n",
    "src_tkn_test = torch.Tensor(tokenized_books['train'][idx:idx+bsz_test]['input_ids']).to(torch.IntTensor())\n",
    "trg_tkn_test = torch.Tensor(tokenized_books['train'][idx:idx+bsz_test]['labels']).to(torch.IntTensor())\n",
    "src_mask_test = torch.BoolTensor(tokenized_books['train'][idx:idx+bsz_test]['attention_mask']).view(bsz_test, -1) \n",
    "print(src_tkn_test.shape, trg_tkn_test.shape, src_mask_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfb2b026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 512])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.eval()\n",
    "with torch.no_grad():\n",
    "    h_state_test = trans.encode(src_tkn_test, src_mask_test)\n",
    "h_state_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c12b85da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_state_test.argmax(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ce6e73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = h_state_test.argmax(axis=1).numpy()\n",
    "# type(out[0]), len(out[0]), out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dcaf68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2e5d06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7607d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d511394c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map['cls_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "de49233d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 101, 7592, 102]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(f\"{tokenizer.special_tokens_map['cls_token']}Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fa2ec0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 102)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.cls_token_id, tokenizer.sep_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "a0813567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'grey'"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(7592)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c4be4907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[101],\n",
       "        [101],\n",
       "        [101],\n",
       "        [101]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "69481fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128, 512])"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_size = 4\n",
    "src_representations_batch = h_state_test\n",
    "src_representations_batch = src_representations_batch.repeat(1, beam_size, 1).view(beam_size*batch_size, -1, model_dimension)\n",
    "src_representations_batch.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "d1507d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 0])"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_token_ids_batch = trg_token_ids_batch.repeat(beam_size, 1)\n",
    "trg_token_ids_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "c461a763",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypotheses_log_probs = torch.zeros((batch_size * beam_size, 1), device=device)\n",
    "had_eos = [[False] for _ in range(hypotheses_log_probs.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f11fd37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f3ad73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7976f72a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f088152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b00e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f87f2622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 100, 100])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_no_look_forward_mask = torch.triu(torch.ones((1, 1, 100, 100), device=device) == 1).transpose(2, 3)\n",
    "trg_no_look_forward_mask.shape\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "cd7a2815",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (5) must match the size of tensor b (2) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [149], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m     num_trg_tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(trg_padding_mask\u001b[38;5;241m.\u001b[39mlong())\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trg_mask, num_trg_tokens\n\u001b[0;32m---> 18\u001b[0m trg_mask, num_trg_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mget_masks_and_count_tokens_trg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrg_token_ids_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m trg_mask\u001b[38;5;241m.\u001b[39mshape, trg_mask, num_trg_tokens\n",
      "Cell \u001b[0;32mIn [149], line 12\u001b[0m, in \u001b[0;36mget_masks_and_count_tokens_trg\u001b[0;34m(trg_token_ids_batch, pad_token_id)\u001b[0m\n\u001b[1;32m      9\u001b[0m     trg_no_look_forward_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtriu(torch\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m, sequence_length, sequence_length), device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#     # logic AND operation (both padding mask and no-look-forward must be true to attend to a certain target token)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     trg_mask \u001b[38;5;241m=\u001b[39m \u001b[43mtrg_padding_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrg_no_look_forward_mask\u001b[49m  \u001b[38;5;66;03m# final shape = (B, 1, T, T)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#     trg_mask = trg_padding_mask\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     num_trg_tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(trg_padding_mask\u001b[38;5;241m.\u001b[39mlong())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (2) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "def get_masks_and_count_tokens_trg(trg_token_ids_batch, pad_token_id):\n",
    "    batch_size = trg_token_ids_batch.shape[0]\n",
    "    device = trg_token_ids_batch.device\n",
    "\n",
    "    # Same as src_mask but we additionally want to mask tokens from looking forward into the future tokens\n",
    "    # Note: wherever the mask value is true we want to attend to that token, otherwise we mask (ignore) it.\n",
    "    sequence_length = trg_token_ids_batch.shape[1]  # trg_token_ids shape = (B, T) where T max trg token-sequence length\n",
    "    trg_padding_mask = (trg_token_ids_batch != pad_token_id).view(batch_size, -1)  # shape = (B, T)\n",
    "    trg_no_look_forward_mask = torch.triu(torch.ones((1,1, sequence_length, sequence_length), device=device) == 1).transpose(2, 3)\n",
    "\n",
    "#     # logic AND operation (both padding mask and no-look-forward must be true to attend to a certain target token)\n",
    "    trg_mask = trg_padding_mask & trg_no_look_forward_mask  # final shape = (B, 1, T, T)\n",
    "#     trg_mask = trg_padding_mask\n",
    "    num_trg_tokens = torch.sum(trg_padding_mask.long())\n",
    "\n",
    "    return trg_mask, num_trg_tokens\n",
    "\n",
    "trg_mask, num_trg_tokens = get_masks_and_count_tokens_trg(trg_token_ids_batch, tokenizer.pad_token_id)\n",
    "trg_mask.shape, trg_mask, num_trg_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2ff7f711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[101, 102]]), torch.Size([1, 2]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = next(trans.parameters()).device\n",
    "pad_token_id = tokenizer.pad_token_id\n",
    "batch_size, S, model_dimension = h_state_test.shape\n",
    "target_multiple_hypotheses_tokens = [[\"[CLS]\"] for _ in range(1)]\n",
    "trg_token_ids_batch = torch.tensor([[101, 102] for tokens in target_multiple_hypotheses_tokens], device=device)\n",
    "trg_token_ids_batch, trg_token_ids_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8113976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_size = 5\n",
    "h_state_test = h_state_test.repeat(1,beam_size,1).view(beam_size*bsz_test, -1, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3e83d7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 128, 512])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_state_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b69a573d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_token_ids_batch = trg_token_ids_batch.repeat(beam_size, 1)\n",
    "trg_token_ids_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b6c1f751",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypotheses_log_probs = torch.zeros((bsz_test * beam_size, 1), device=device)\n",
    "had_eos = [[False] for _ in range(hypotheses_log_probs.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb88d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans.decode(h_state_test, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "5e4aabc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_decoding(beam_size, tokenizer, transformer, src_representations_batch, src_mask, max_target_tokens=100):\n",
    "    device = next(transformer.parameters()).device\n",
    "    pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "    # Initial prompt is the beginning/start of the sentence token. Make it compatible shape with source batch => (B,1)\n",
    "    batch_size, S, model_dimension = src_representations_batch.shape\n",
    "    target_multiple_hypotheses_tokens = [[\"[CLS]\"] for _ in range(batch_size)]\n",
    "    trg_token_ids_batch = torch.tensor([[101] for tokens in target_multiple_hypotheses_tokens], device=device)\n",
    "    \n",
    "    # Repeat so that source sentence representations are repeated contiguously, say we have [s1, s2] we want\n",
    "    # [s1, s1, s2, s2] and not [s1, s2, s1, s2] where s1 is single sentence representation with shape=(S, D)\n",
    "    # where S - max source token-sequence length, D - model dimension\n",
    "    src_representations_batch = src_representations_batch.repeat(1, beam_size, 1).view(beam_size*batch_size, -1, model_dimension)\n",
    "    trg_token_ids_batch = trg_token_ids_batch.repeat(beam_size, 1)\n",
    "\n",
    "    hypotheses_log_probs = torch.zeros((batch_size * beam_size, 1), device=device)\n",
    "    had_eos = [[False] for _ in range(hypotheses_log_probs.shape[0])]\n",
    "\n",
    "    while True:\n",
    "        trg_mask, _ = get_masks_and_count_tokens_trg(trg_token_ids_batch, pad_token_id)\n",
    "        # Shape = (B*BS*T, V) T - current token-sequence length, V - target vocab size, BS - beam size, B - batch\n",
    "        predicted_log_distributions = transformer.decode(src_representations_batch, trg_token_ids_batch, trg_mask)\n",
    "\n",
    "        # Extract only the indices of last token for every target sentence (we take every T-th token)\n",
    "        # Shape = (B*BS, V)\n",
    "        num_of_trg_tokens = trg_token_ids_batch.shape[-1]\n",
    "        predicted_log_distributions = predicted_log_distributions[num_of_trg_tokens - 1::num_of_trg_tokens]\n",
    "\n",
    "        # This time extract beam_size number of highest probability tokens (compare to greedy's arg max)\n",
    "        # Shape = (B*BS, BS)\n",
    "        latest_token_log_probs, most_probable_token_indices = torch.topk(predicted_log_distributions, beam_size, dim=-1, sorted=True)\n",
    "\n",
    "        # Don't update the hypothesis which had EOS already (pruning)\n",
    "        latest_token_log_probs.masked_fill(torch.tensor(had_eos == True), float(\"-inf\"))\n",
    "\n",
    "        # Calculate probabilities for every beam hypothesis (since we have log prob we add instead of multiply)\n",
    "        # Shape = (B*BS, BS)\n",
    "        hypotheses_pool_log_probs = hypotheses_log_probs + latest_token_log_probs\n",
    "        # Shape = (B, BS, BS)\n",
    "        most_probable_token_indices = most_probable_token_indices.view(batch_size, beam_size, beam_size)\n",
    "        hypotheses_pool_log_probs = hypotheses_pool_log_probs.view(batch_size, beam_size, beam_size)\n",
    "        # Shape = (B, BS*BS)\n",
    "        hypotheses_pool_log_probs = torch.flatten(hypotheses_pool_log_probs, start_dim=-1)\n",
    "\n",
    "        # Figure out indices of beam_size most probably hypothesis for every target sentence in the batch\n",
    "        # Shape = (B, BS)\n",
    "        new_hypothesis_log_probs, next_hypothesis_indices = torch.topk(hypotheses_pool_log_probs, beam_size, dim=-1, sorted=True)\n",
    "\n",
    "        # Create new target ids batch\n",
    "        hypotheses_log_probs_tmp = torch.empty((batch_size * beam_size, 1))\n",
    "\n",
    "        T = trg_token_ids_batch.shape[-1]\n",
    "        new_trg_token_ids_batch = torch.empty((batch_size * beam_size, T + 1))\n",
    "\n",
    "        next_hypothesis_indices = next_hypothesis_indices.cpu().numpy()\n",
    "        # Prepare new hypotheses for the next iteration\n",
    "        for b_idx, indices in enumerate(next_hypothesis_indices):\n",
    "            for h_idx, token_index in indices:\n",
    "                row, column = token_index / beam_size, token_index % beam_size\n",
    "                hypothesis_index = b_idx * beam_size + h_idx\n",
    "\n",
    "                new_token_id = most_probable_token_indices[b_idx, row, column]\n",
    "                if had_eos[hypothesis_index]:\n",
    "                    new_trg_token_ids_batch[hypothesis_index, :-1] = trg_token_ids_batch[hypothesis_index, :]\n",
    "                else:\n",
    "                    new_trg_token_ids_batch[hypothesis_index, :-1] = trg_token_ids_batch[b_idx * beam_size + row, :]\n",
    "                    new_trg_token_ids_batch[hypothesis_index, -1] = new_token_id\n",
    "\n",
    "                if had_eos[hypothesis_index]:\n",
    "                    hypotheses_log_probs_tmp[hypothesis_index] = hypotheses_log_probs[hypothesis_index]\n",
    "                else:\n",
    "                    hypotheses_log_probs_tmp[hypothesis_index] = new_hypothesis_log_probs[hypothesis_index]\n",
    "\n",
    "                if new_token_id == tokenizer.eos_token_id:\n",
    "                    had_eos[hypothesis_index] = True\n",
    "\n",
    "        # Update the current hypothesis probabilities\n",
    "        hypotheses_log_probs = hypotheses_log_probs_tmp\n",
    "        trg_token_ids_batch = new_trg_token_ids_batch\n",
    "\n",
    "        if all(had_eos) or num_of_trg_tokens == max_target_tokens:\n",
    "            break\n",
    "\n",
    "    #\n",
    "    # Selection and post-processing\n",
    "    #\n",
    "\n",
    "    target_multiple_hypotheses_tokens = []\n",
    "    trg_token_ids_batch_numpy = trg_token_ids_batch.cpu().numpy()\n",
    "    for hypothesis_ids in trg_token_ids_batch_numpy:\n",
    "        target_multiple_hypotheses_tokens.append([tokenizer.decode(token_id) for token_id in hypothesis_ids])\n",
    "\n",
    "    # Step 1: Select the most probable hypothesis out of beam_size hypotheses for each target sentence\n",
    "    hypotheses_log_probs = hypotheses_log_probs.view(batch_size, beam_size)\n",
    "    most_probable_hypotheses_indices = torch.argmax(hypotheses_log_probs, dim=-1).cpu().numpy()\n",
    "    target_sentences_tokens = []\n",
    "    for b_idx, index in enumerate(most_probable_hypotheses_indices):\n",
    "        target_sentences_tokens.append(target_multiple_hypotheses_tokens[b_idx * beam_size + index])\n",
    "\n",
    "    # Step 2: Post process the sentences - remove everything after the EOS token\n",
    "    target_sentences_tokens_post = []\n",
    "    for target_sentence_tokens in target_sentences_tokens:\n",
    "        try:\n",
    "            target_index = target_sentence_tokens.index(EOS_TOKEN) + 1\n",
    "        except:\n",
    "            target_index = None\n",
    "\n",
    "        target_sentence_tokens = target_sentence_tokens[:target_index]\n",
    "        target_sentences_tokens_post.append(target_sentence_tokens)\n",
    "\n",
    "    return target_sentences_tokens_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b4bd4791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(101)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
